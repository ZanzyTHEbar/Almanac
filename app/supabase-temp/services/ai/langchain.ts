import { ChatOpenAI } from '@langchain/openai'
import { HumanMessage, BaseMessage } from '@langchain/core/messages'
import { END, MessageGraph } from '@langchain/langgraph'
import type { GraphState } from '@static/types'
import { prompt } from './prompt'

/**
 * Verdant AI Agentic Pipeline
 *
 * This pipeline is broken up into Agents that are responsible for different tasks.
 * The pipeline is designed to be flexible and extensible, allowing for the addition of new agents and tools as needed.
 * The agents communicate with each other through a shared state object, allowing them to pass information and results between each other as needed.
 *
 * The pipeline utilizes the latest AI technologies, including LLMLingua, FLARE RAG, and Self-Correction, to provide accurate and reliable solutions to user queries.
 *
 * Each agent in the pipeline is responsible for a specific task, and together they work together to generate a solution to the user query.
 *
 * Each Agent implements the Model Fallback pattern, which allows it to fall back to a more complex model if the simpler model fails to generate a solution.
 *
 * The pipeline is as follows:
 * 1. UserProxyAgent: Responsible for handling user input.
 *  - Implements a LongTermMemory to store user specific information and preferences.
 *      - The LongTermMemory is used to store information about the user's preferences, history, and context.
 *      - The LongTermMemory is broken into two parts: the cache and the knowledge base.
 *          - The cache stores information that is relevant to the current query and is used to speed up the response time.
 *          - The knowledge base stores information that is relevant to the user's history and preferences and is used to provide personalized responses.
 *          - Information moves into the cache from the knowledge base as it becomes relevant to the current query.
 *          - The cache is periodically cleared to make room for new information, based on the amount of time that has passed since the information was last accessed.
 * - Implements a Self-Correction mechanism to improve the quality of the solution.
 * - Implements a Knowledge base to store successful solutions and examples for future reference.
 *     - This also implements its own cache and knowledge base to store successful solutions and examples for future reference.
 * - Implements a knowledge base of information that is relevant to the application domain, not to the user specifically.
 *     - Implements a cache of information that is relevant to the current query and is used to speed up the response time.
 * - checking all caches and knowledge bases (Self-Correction with query analysis and FLARE RAG)
 *      - If there is a relevant cache or knowledge base, generating examples from previous successful actions that are relevant
 *  - If there is no relevant cache or knowledge base, moving on to the next step
 *  - converting the user query (and any retrieved information, examples, and/or knowledge) into a prompt format that can be used by the system.
 *      - Using an LLMLingua pattern to optimize the prompts token usage.
 *  - sending the prompt to the next agent in the pipeline
 * 2. DecisionEngine: Responsible for generating a plan for a given query.
 *  - Uses the Plan and Execute pattern to generate a plan for a given query.Chain of Thought, Tree of Thought, and Graph of Thought.
 *  - The plan is generated by breaking the incoming task into smaller sub-tasks, each of which is its own plan, and then indicating which external tool together with tool input to retrieve evidence.
 *  - Generate a plan using variable substitution and external tools.
 * 3. ExecutorAgent: Responsible for executing the plan generated by the DecisionEngine.
 *  - The Decision Engine generates a detailed plan, breaking down the query into specific tasks (e.g., #E1, #E2, #E3) that need to be executed to gather information or perform actions.
 *  - As each step is executed, the output is substituted into the placeholder variable of the next step and fed back into the ExecutorAgent.
 *  - Each task is executed by calling the appropriate external tool with the input provided in the plan.
 *  - The ExecutorAgent keeps track of the state of the plan and the results of each step.
 *  - The ExecutorAgent only implements fallback to models capable of function calling.
 * 4. SolverAgent: Responsible for solving the query based on the results of the plan execution.
 *  - The SolverAgent takes the results of the plan execution and uses them to solve the original query.
 *  - Implements Self-Correction and Self-Reflection to improve the quality of the solution.
 *  - Implements a cache and knowledge base to store successful solutions and examples for future reference.
 *  - The SolverAgent provides the final solution to the UserProxyAgent, which then presents it to the user.
 */

const graphState = {
    task: {
        value: null,
    },
    planString: {
        value: null,
    },
    steps: {
        value: (a: Array<string>, b: Array<string>) => a.concat(b),
        default: () => [],
    },
    results: {
        value: null,
    },
    result: {
        value: null,
    },
}
